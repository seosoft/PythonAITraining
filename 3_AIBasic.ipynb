{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd20dbcc-ddd1-4dcf-8545-2343267e27b5",
   "metadata": {},
   "source": [
    "# Azure Cognitive Services で AI プログラミング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558b8cb-29c5-4e8d-afbf-84a853de0631",
   "metadata": {},
   "source": [
    "## 0. 準備 - Cognitive Services 接続情報を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a98a7-1ef4-486c-bab0-72a42d12446b",
   "metadata": {},
   "source": [
    "このハンズオンでは Azure Cognitive Services で提供されている **事前構築済みの AI** を利用して AI 開発を体験します。\n",
    "\n",
    "最初に Cognitive Services の接続情報が正しく設定されているかを確認します。\n",
    "\n",
    "> 集合形式のハンズオンではあらかじめ接続情報が設定されているかもしれません。  \n",
    "> その場合は、以下のセルを実行すると、エンドポイントとキーの値が表示されます。\n",
    ">\n",
    "> [**Cognitive リソースの作成**](./a01_createcog.ipynb) および [**ハンズオンの環境構築**](./0_setup.ipynb) を実施する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b364b0d-3749-4f07-84d6-ad609ffa4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60904982-f9a4-43d6-90fb-e8157afdb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cognitive Services 利用のために Endpoint と Key とを読み込みます\n",
    "load_dotenv()\n",
    "cog_endpoint = os.getenv('COG_SERVICE_ENDPOINT')\n",
    "cog_key = os.getenv('COG_SERVICE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f3ddb-2c7a-457f-ba6f-b6b10afd9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Endpoint: \" + cog_endpoint)\n",
    "print(\"Key: \" + cog_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc034178-852e-4f69-bafc-9fbff83eed07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618aafd-d1c7-4ad7-a31f-df6c6fa7599b",
   "metadata": {},
   "source": [
    "## 1. 画像分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94358f95-a3dc-445a-b50c-584007111dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396fc5af-7982-4ec5-b352-d8a9dfeb9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像のパスを決定\n",
    "image_path = os.path.join('data', 'vision', 'image1.jpg')\n",
    "#image_path = os.path.join('data', 'vision', 'image2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821b9b0-31d2-4cc9-b3ca-65dcf228499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(image_path)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27620c0-152d-47aa-b635-30e8cd67eff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a client for the computer vision service\n",
    "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09565b12-06d4-4c53-b778-cab4c06e7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "features = ['Description', 'Tags', 'Adult', 'Objects', 'Faces']\n",
    "#analysis = computervision_client.analyze_image_in_stream(image_stream, visual_features=features)\n",
    "analysis = computervision_client.analyze_image_in_stream(image_stream, visual_features=features, language=\"ja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ea08e-df18-48c2-8c4b-d8b3a101259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in analysis.tags:\n",
    "    print(f'{tag.name} ({(tag.confidence * 100):.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661fc653-a604-457a-a817-ad8824c0fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "for face in analysis.faces:\n",
    "    bound = face.face_rectangle\n",
    "  \n",
    "    rect = patches.Rectangle((bound.left, bound.top),\n",
    "                     bound.width,\n",
    "                     bound.height,\n",
    "                     linewidth=4,\n",
    "                     edgecolor='red',\n",
    "                     fill = False)\n",
    "\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'{len(analysis.faces)}人の人が写っています')\n",
    "\n",
    "for face in analysis.faces:\n",
    "    print(f'{\"男性\" if face.gender == \"Male\" else \"女性\"} {face.age}歳')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0efca-fe08-46a7-a3d8-fa81780008a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
